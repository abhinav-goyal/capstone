{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Implementation\n",
    "\n",
    "Moving to Keras for the implementation to quickly churn out models. The goal of this notebook is to achieve numbers similar/better to those achieved using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import pylab as P\n",
    "import skimage\n",
    "import h5py\n",
    "import PIL.Image as Image\n",
    "import functools\n",
    "from sklearn.cross_validation import train_test_split as ttsplit\n",
    "import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras # the point of this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ag/projects/ml_nanodegree/clean_repo/capstone/src\n",
      "/home/ag/projects/ml_nanodegree/clean_repo/capstone/data\n"
     ]
    }
   ],
   "source": [
    "# helper function to read a pickle file\n",
    "# TODO: move this to helpers file\n",
    "def read_pickle_file(f_name):\n",
    "    f = open(f_name, 'r')\n",
    "    return pickle.load(f)\n",
    "\n",
    "\n",
    "print os.getcwd()\n",
    "data_dir = os.path.join(os.path.split(os.getcwd())[0], 'data')\n",
    "print data_dir\n",
    "\n",
    "def get_data_path(f_name):\n",
    "    return os.path.join(data_dir, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    'train_single_data.pkl',\n",
    "    'train_single_labels.pkl',\n",
    "    'valid_single_data.pkl',\n",
    "    'valid_single_labels.pkl',\n",
    "    'test_single_data.pkl',\n",
    "    'test_single_labels.pkl',\n",
    "]\n",
    "\n",
    "\n",
    "train_images, train_labels, valid_images, valid_labels, test_images, test_labels  = \\\n",
    "    [read_pickle_file(get_data_path(f_name)) for f_name in file_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594368, 32, 32, 1)\n",
      "(594368,)\n",
      "(26032, 32, 32, 1)\n",
      "(26032,)\n"
     ]
    }
   ],
   "source": [
    "print train_images.shape\n",
    "print train_labels.shape\n",
    "print test_images.shape\n",
    "print test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_set = set(train_labels)\n",
    "assert(len(label_set) == 10)\n",
    "num_labels = len(label_set)\n",
    "labels = range(10)\n",
    "assert(len(label_set.difference(set(labels))) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define an accuracy measure for this model\n",
    "def accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "        How many places did we get right?\n",
    "    \"\"\"\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == labels)) / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## time to define the model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "## let's add a conv and pooling layer\n",
    "## let's follow the same model we used with TF\n",
    "\n",
    "## convolve from 32x32x1 to 28x28x16\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', input_shape=(32, 32, 1)))\n",
    "# let's pool this - go to 14x14x16\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None))\n",
    "# pass through a filter\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "## convolve and pool and filter again\n",
    "## go to 32x10x10\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(14, 14, 16)))\n",
    "## go to 32x5x5\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "## and again\n",
    "# go to 64x3x3\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', input_shape=(5, 5, 32)))\n",
    "# go to 64x1x1\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=None))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "## Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "## Dropout\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "## slap on the FCN at the end\n",
    "## h1\n",
    "model.add(Dense(output_dim=64, input_dim=64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# h2\n",
    "model.add(Dense(output_dim=32, input_dim=128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "## output\n",
    "model.add(Dense(output_dim=len(labels), input_dim=32))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "# specify the loss\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0999 - acc: 0.9721    \n",
      "Epoch 2/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0994 - acc: 0.9725    \n",
      "Epoch 3/10\n",
      "594368/594368 [==============================] - 22s - loss: 0.0991 - acc: 0.9724    \n",
      "Epoch 4/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0986 - acc: 0.9725    \n",
      "Epoch 5/10\n",
      "594368/594368 [==============================] - 22s - loss: 0.0978 - acc: 0.9729    \n",
      "Epoch 6/10\n",
      "594368/594368 [==============================] - 22s - loss: 0.0978 - acc: 0.9729    \n",
      "Epoch 7/10\n",
      "594368/594368 [==============================] - 22s - loss: 0.0974 - acc: 0.9729    \n",
      "Epoch 8/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0969 - acc: 0.9731    \n",
      "Epoch 9/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0966 - acc: 0.9731    \n",
      "Epoch 10/10\n",
      "594368/594368 [==============================] - 21s - loss: 0.0965 - acc: 0.9732    \n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_images, train_labels, batch_size=512, nb_epoch=10) # 60 epochs before this - > total 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25920/26032 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21448607176436957, 0.94510602335586968]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
